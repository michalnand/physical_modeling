network init start

hyperparameters
init_weight_range 0.000000 ,xavier
learning_rate 0.000200
lambda1 0.000001
lambda2 0.000001
dropout 0.020000
minibatch size 32

   DENSE CONVOLUTION  [   32    32     8] [    3     3     8] [   32    32    16] [       576          8][    598016]
                RELU  [   32    32    16] [    1     1     1] [   32    32    16] [         0          0][     32768]
   DENSE CONVOLUTION  [   32    32    16] [    3     3     8] [   32    32    24] [      1152          8][   1187840]
                RELU  [   32    32    24] [    1     1     1] [   32    32    24] [         0          0][     49152]
   DENSE CONVOLUTION  [   32    32    24] [    3     3     8] [   32    32    32] [      1728          8][   1777664]
                RELU  [   32    32    32] [    1     1     1] [   32    32    32] [         0          0][     65536]
   DENSE CONVOLUTION  [   32    32    32] [    3     3     8] [   32    32    40] [      2304          8][   2367488]
                RELU  [   32    32    40] [    1     1     1] [   32    32    40] [         0          0][     81920]
         MAX POOLING  [   32    32    40] [    2     2     1] [   16    16    40] [         0          0][     81920]
   DENSE CONVOLUTION  [   16    16    40] [    3     3     8] [   16    16    48] [      2880          8][    739328]
                RELU  [   16    16    48] [    1     1     1] [   16    16    48] [         0          0][     24576]
   DENSE CONVOLUTION  [   16    16    48] [    3     3     8] [   16    16    56] [      3456          8][    886784]
                RELU  [   16    16    56] [    1     1     1] [   16    16    56] [         0          0][     28672]
   DENSE CONVOLUTION  [   16    16    56] [    3     3     8] [   16    16    64] [      4032          8][   1034240]
                RELU  [   16    16    64] [    1     1     1] [   16    16    64] [         0          0][     32768]
   DENSE CONVOLUTION  [   16    16    64] [    3     3     8] [   16    16    72] [      4608          8][   1181696]
                RELU  [   16    16    72] [    1     1     1] [   16    16    72] [         0          0][     36864]
         MAX POOLING  [   16    16    72] [    2     2     1] [    8     8    72] [         0          0][     36864]
         CONVOLUTION  [    8     8    72] [    3     3    32] [    8     8    32] [     20736         32][   1329152]
                RELU  [    8     8    32] [    1     1     1] [    8     8    32] [         0          0][      4096]
                  FC  [    8     8    32] [    1     1     3] [    1     1     3] [      6144          3][     12294]

input_geometry  [32 32 8]
output_geometry [1 1 3]
network flops operations 11589638 FLOPS, 0.011590 GFLOPS
init DONE

network destructor done
